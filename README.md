# Prompt Refinement Candidate Generator

This repository provides a **multi-variant prompt refinement and image generation pipeline** built on **Stable Diffusion XL (SDXL)**, LoRA adapters, CLIP scoring, and aesthetic prediction.  
It generates multiple candidate images from input prompts, iteratively refining both **WHAT** (content) and **HOW** (style) descriptions using an LLM.  

---

## Features
- **Prompt Expansion & Refinement**  
  Expands terse prompts into rich narrative descriptions and converts them into SDXL-compatible tags.  
  Iteratively refines prompts based on CLIP similarity and aesthetic scoring.  

- **Multi-Variant Image Generation**  
  Runs prompt variations across models, LoRAs, seeds, and weights.  

- **Automated Scoring**  
  - **CLIP score**: semantic alignment with the user‚Äôs original prompt.  
  - **Aesthetic score**: quality of the rendered image.  

- **Captioning & Metadata**  
  Uses a vision-language model to caption generated images and stores candidate metadata in JSON.  

- **LoRA Integration**  
  Automatically applies LoRA adapters with customizable triggers and weights.  

---

## Installation

### 1. Clone repository
```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

### 2. Create a virtual environment
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies
```bash
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
pip install diffusers transformers accelerate safetensors pillow
pip install llama-cpp-python colorlog
```

---

## Hugging Face Token Setup

This project retrieves **CLIP** and **captioning models** from Hugging Face.  
You must set your HF token before running:

```bash
huggingface-cli login
# OR set environment variable
export HUGGINGFACE_HUB_TOKEN=hf_your_token_here
```

If you don‚Äôt have a token yet, create one at:  
üëâ https://huggingface.co/settings/tokens

---

## Usage

### Basic run
```bash
python generate-candidates.py
```

- Input prompts are defined in `USER_PROMPTS` inside the script.  
- Outputs are saved under `multi_variant_runs/<timestamp>/`.  
  - Candidate images (`*.png`)  
  - Metadata JSON (`*.json`)  

### Example prompts (WHAT)
- ‚ÄúTowering world-tree with roots piercing starlit sky, branches cradling fragments of glowing cities‚Äù  
- ‚ÄúForgotten underwater temple, coral-encrusted statues of strange gods, shafts of light piercing the surface‚Äù  

### Example prompts (HOW)
- ‚ÄúCinematic digital painting style, dramatic rim lighting, glowing highlights‚Äù  
- ‚ÄúDreamlike surrealism, glowing desert horizon, radiant reflections‚Äù  

---

## Project Structure
- `generate-candidates.py` ‚Äî Main pipeline for generating, refining, and scoring prompts.  
- `models/` ‚Äî Expected directory for SDXL checkpoints and LoRA adapters.  
- `multi_variant_runs/` ‚Äî Output directory (auto-created per run).  

---

## Notes
- Ensure you have enough **GPU VRAM** (recommended ‚â• 24GB).  
- The script aggressively frees memory after each round to allow large model usage.  
- If models are not found locally, Hugging Face Hub will be used (hence the required HF token).  

---

## License
MIT License (adapt as needed).  
